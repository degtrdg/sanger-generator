{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_int = 128\n",
    "batch_size = 16\n",
    "training_steps = 500\n",
    "\n",
    "def number_binary(number: int) -> list[int]:\n",
    "    return [int(bit) for bit in bin(number)[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"NGNATCAGGGTATATTGCTGGTTCATGCCTTCTGGAGGACCTTGTCCACCATGACTGTATCNATCAACGATAATAGTCTTCCTGGCCTGAGTACTGCTGTGGTGGGCCCTGTTGAGGAGGTCTATAGGGAGGAATCTGTCTCTGACCCATCATATGATTGCCTTGGTTAACTTGACCCATCATTCCCATAGGTGGCTGCTGTCCTTGGTAATGCTGTCCGCCTCCCTGTGGCATATTGTATTGCTGAGAAGGAGGCTGCTGATGCATCATTGGACCTTGGTTTGGCTGCATACTCATATTTGGTCTGGGACCATAGTTTCCCATTGGTTGTCCCTGACTCATTGTCATCTGATTCTGTACTGGCATGCTCTGTGATGATGGCACAGAATGGTTGTAACCTCCCATGGATCCATGGCTACTTGAAGGCATATTCATGGAACTGTTTGTCATATTGAGTTGATTGGGTCCAGGTCCCTGCATAGGCATATGGTTAGGCCCAGGCATCTGGCCGTTCATCTGGTTCTGCATGTGCGGTGCANGAGGACCCCCACCTACCATTCCATCTGAAGGCATGTTGTGAAAACGTGGAAGTGGGGGANGGGCCNCTCTGAATCATCCCTCCNAGGACCCANANGCATATTCTGTGNGGGTGGNGCTGGGAAAGAGACTGCATATTTTGATANAATCTGGCTATTGTANCAAGGTATACCAAGTTTGTGTGCAACATCTGCTGANACTGAAACACTCTGAGTCTTCCTTATCTGAGANTCCATAAAACTGAAAAGANGTTATGTCATCCAANTCTTCTNATCGCANCGGATGACTCCCCTGCTCCTGCCCGGGCCCAAAGCANAANTGTGCNCCTCNCATATCGGAATCCNGCCCCGGNGANGNAACCNTNGGCAAATGCTGAGAATCCNCTTNAAANAAAACTCCTNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_even_data(max_int: int, batch_size: int=16) -> tuple[list[int], list[list[int]]]:\n",
    "    # Sample batch_size number of integers in range 0 to max_int.\n",
    "    sampled_integers = np.random.randint(0, max_int, batch_size)\n",
    "\n",
    "    # Create a list of labels, all ones, because all numbers are even.\n",
    "    labels = [1] * batch_size\n",
    "\n",
    "    # Generate a list of binary numbers for training.\n",
    "    data = [number_binary(num) for num in sampled_integers]\n",
    "\n",
    "    # Get the number of binary places needed to represent the maximum number.\n",
    "    max_length = int(np.log2(max_int)) + 1\n",
    "\n",
    "    # Add padding in front of each number to regularize it\n",
    "    data = [[0]*(max_length - len(num)) + num for num in data]\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# Defining the Generator class for the Sanger sequencing task\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_length, hidden_size, output_size=4):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_length, hidden_size=hidden_size, batch_first=True)\n",
    "        self.dense_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.dense_layer(lstm_out)\n",
    "        return self.activation(output)\n",
    "\n",
    "# Example input size (batch_size, sequence_length, one_hot_length)\n",
    "input_length = 4  # one-hot encoding size for nucleotides A, C, G, T\n",
    "hidden_size = 64  # LSTM hidden size\n",
    "sequence_length = 10  # Example sequence length\n",
    "\n",
    "# Test the generator with random data\n",
    "g = Generator(input_length, hidden_size)\n",
    "example_input = torch.rand((batch_size, sequence_length, input_length)) # Random one-hot encoded sequences\n",
    "example_output = g(example_input)\n",
    "\n",
    "# Check the output shape, it should be (batch_size, sequence_length, 4)\n",
    "example_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "  Real predictions: [1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 50:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 100:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 150:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 200:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 250:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 300:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 350:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 400:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Step 450:\n",
      "  Real predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  Generated predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "  True labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "max_int = 128\n",
    "batch_size = 16\n",
    "training_steps = 500\n",
    "input_length = int(np.log2(max_int)) + 1\n",
    "\n",
    "g = Generator(input_length)\n",
    "d = Discriminator(input_length)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "g_optim = torch.optim.Adam(g.parameters(), lr=1e-3)\n",
    "d_optim = torch.optim.Adam(d.parameters(), lr=1e-3)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for i in range(training_steps):\n",
    "    g_optim.zero_grad()\n",
    "\n",
    "    # I want to generate data with the generator, so I need to put something in it first. I'll be putting in noise.\n",
    "    noise = torch.randint(0,2, (batch_size, input_length)).float()\n",
    "    g_data = g(noise)\n",
    "\n",
    "    # I want real data to put inside the discriminator\n",
    "    true_data, true_labels = generate_even_data(max_int=max_int, batch_size=batch_size)\n",
    "    true_labels = torch.tensor(true_labels).float()\n",
    "    true_data = torch.tensor(true_data).float()\n",
    "\n",
    "    # Use what the discriminator thinks as a way to evaluate the performance of the generator.\n",
    "    g_d_out = d(g_data).view(-1)\n",
    "    g_loss = loss(g_d_out, true_labels)\n",
    "    g_loss.backward()\n",
    "    g_optim.step()\n",
    "\n",
    "    # Clear the gradients from the filled-up expression graph that included the discriminator parameters\n",
    "    d_optim.zero_grad()\n",
    "\n",
    "    # Get the loss from the discriminator looking at the true data\n",
    "    d_true_data = d(true_data).view(-1)\n",
    "    # true_labels was not the result of any of the parameters in any of the neural networks so no need to detach\n",
    "    d_true_loss = loss(d_true_data, true_labels)\n",
    "\n",
    "    if i % 50 == 0:  # N is the frequency with which you want to print the stats\n",
    "        with torch.no_grad():  # Avoid tracking computations\n",
    "            true_predictions = torch.round(d_true_data).int()\n",
    "            generated_predictions = torch.round(g_d_out.detach()).int()\n",
    "            print(f'Step {i}:')\n",
    "            print(f'  Real predictions: {true_predictions.tolist()}')\n",
    "            print(f'  Generated predictions: {generated_predictions.tolist()}')\n",
    "            print(f'  True labels: {true_labels.int().tolist()}')\n",
    "\n",
    "    # Get the loss from the discriminator looking at the generated data.\n",
    "    d_gen_loss = loss(g_d_out.detach(), true_labels)\n",
    "    d_loss = (d_true_loss + d_gen_loss) / 2\n",
    "    d_loss.backward()\n",
    "    d_optim.step()\n",
    "\n",
    "    writer.add_scalar('Generator Loss', g_loss.item(), i)\n",
    "    writer.add_scalar('Discriminator Loss', d_loss.item(), i)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
